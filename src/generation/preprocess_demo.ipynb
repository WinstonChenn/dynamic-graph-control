{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349d1cc6-356a-4b20-9dd0-5b67ac01a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import argparse\n",
    "import shutil\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bbc1ab-129c-416c-8387-877239cbcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dynamic_graph(edges, window_size): \n",
    "    '''\n",
    "    returns a dynamic graph\n",
    "    inputs: \n",
    "        edges (|E| x 3 matrix) : each row represents a temporal edge (u, v, t)\n",
    "        widnow_size (int) : the time range of each graph in the dynamic graph\n",
    "    \n",
    "    outputs: \n",
    "        graphs (list of static graphs)\n",
    "    '''\n",
    "    \n",
    "    def process_edges(edges): \n",
    "        '''first sort edges by time, then remap edge times to integer increments ie. [0, total_timesteps]'''\n",
    "        # sort edges by time\n",
    "        edges = edges[np.argsort(edges[:, 2]), :]\n",
    "        \n",
    "        # remap edge times to integer increments\n",
    "        edges_remapped = np.zeros(edges.shape)\n",
    "        t_original = edges[0, 2]\n",
    "        t_remapped = 0\n",
    "        for t in range(edges.shape[0]): \n",
    "            if edges[t, 2] > t_original: \n",
    "                t_original = edges[t, 2]\n",
    "                t_remapped += 1\n",
    "\n",
    "            edges_remapped[t, :] = np.array([edges[t, 0], edges[t, 1], t_remapped])\n",
    "\n",
    "        return edges_remapped\n",
    "    \n",
    "    edges = process_edges(edges)\n",
    "    graphs = []\n",
    "    edge_times = edges[:, 2]\n",
    "    total_timesteps = np.unique(edge_times).shape[0] // window_size # floor divide ignores the remainder timesteps\n",
    "    \n",
    "    # iterate through temporal edges and create total_timesteps static graphs\n",
    "    for t in range(total_timesteps): \n",
    "        # create a mask that selects edges and nodes within the range [t * window_size, (t+1) * window_size]\n",
    "        t_start = t * window_size\n",
    "        t_end = (t + 1) * window_size\n",
    "        mask_start = (edge_times >= t_start).astype(int)\n",
    "        mask_end = (edge_times < t_end).astype(int)\n",
    "        mask = (mask_start + mask_end) == 2\n",
    "        edges_t = edges[mask, :2]\n",
    "        \n",
    "        # create a static graph using all the edges and nodes within the range [t * window_size, (t+1) * window_size]\n",
    "        g = nx.Graph()\n",
    "        g.add_edges_from(edges_t)\n",
    "        graphs.append(g)\n",
    "    \n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d29c5-b380-4e2e-9eea-96bef42e1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 0 # integers 0-6 map to dataset choices\n",
    "dataset_params = {0: {'path': 'CollegeMsg.txt', 'window_size': 2000}, # https://snap.stanford.edu/data/CollegeMsg.html\n",
    "                  1: {'path': 'email-Eu-core-temporal.txt', 'window_size': 5000}, # https://snap.stanford.edu/data/email-Eu-core.html\n",
    "                  2: {'path': 'sx-mathoverflow.txt', 'window_size': 12000}, # https://snap.stanford.edu/data/sx-mathoverflow.html\n",
    "                  3: {'path': 'soc-sign-bitcoinalpha.csv', 'window_size': 100}, # https://snap.stanford.edu/data/soc-sign-bitcoin-alpha.html\n",
    "                  4: {'path': 'soc-sign-bitcoinotc.csv', 'window_size': 1000}, # https://snap.stanford.edu/data/soc-sign-bitcoin-otc.html\n",
    "                  5: {'path': 'soc-redditHyperlinks-body.tsv', 'window_size': 10000},\n",
    "                  6: {'path': 'soc-redditHyperlinks-title.tsv', 'window_size': 10000}}\n",
    "\n",
    "# fill in the data path and download datasets to path\n",
    "# path = ...\n",
    "\n",
    "if data in [0, 1, 2]:\n",
    "    edges = np.loadtxt(f'{path}/{dataset_params[real][\"path\"]}')\n",
    "elif data in [3, 4]:\n",
    "    edges = np.genfromtxt(f'{path}/{dataset_params[real][\"path\"]}', delimiter=',')[:, [0, 1, 3]]\n",
    "elif data in [5, 6]:\n",
    "    edges = pd.read_csv(f'{path}/{dataset_params[real][\"path\"]}', delimiter='\\t')\n",
    "\n",
    "graphs = create_dynamic_graph(edges, window_size=window_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
